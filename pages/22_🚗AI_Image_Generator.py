# import streamlit as st
# import openai
# from PIL import Image
# import io
# from dotenv import load_dotenv
# import os

# # Charger les variables d'environnement
# load_dotenv()

# # Configuration de l'API OpenAI
# openai.api_key = os.getenv('OPENAI_API_KEY')

# # Fonction pour g√©n√©rer une image √† partir du texte
# def generate_image_from_text(text_prompt):
#     response = openai.Image.create(
#         prompt=text_prompt,
#         n=1,
#         size="1024x1024"  # Vous pouvez ajuster la taille
#     )
#     image_url = response['data'][0]['url']
#     return image_url

# # Fonction pour interpr√©ter une image (par exemple, reconnaissance de texte)
# def interpret_image(image):
#     # Pour cette d√©mo, nous allons simplement afficher l'image.
#     # Vous pouvez int√©grer une API de reconnaissance d'image ici (par exemple, OpenAI CLIP, Google Vision, etc.).
#     st.image(image, caption='Image interpr√©t√©e')

# # Application Streamlit
# st.title('G√©n√©rateur d\'image √† partir de texte')

# # Entr√©e utilisateur
# text_input = st.text_input('Entrez une description pour g√©n√©rer une image', '')

# if text_input:
#     # G√©n√©rer l'image √† partir du texte
#     with st.spinner('G√©n√©ration de l\'image...'):
#         image_url = generate_image_from_text(text_input)
    
#     st.image(image_url, caption='Image g√©n√©r√©e', use_column_width=True)

# # Section d'analyse d'image
# st.subheader('Interpr√©tez une image')

# uploaded_file = st.file_uploader("T√©l√©chargez une image pour l'interpr√©tation", type=["jpg", "jpeg", "png"])

# if uploaded_file is not None:
#     # Affichage de l'image t√©l√©charg√©e
#     image = Image.open(uploaded_file)
#     st.image(image, caption="Image t√©l√©charg√©e", use_column_width=True)

#     # Interpr√©tation de l'image
#     with st.spinner('Interpr√©tation de l\'image...'):
#         interpret_image(image)


# import streamlit as st
# import openai
# from PIL import Image
# import io
# from dotenv import load_dotenv
# import os

# # Charger les variables d'environnement
# load_dotenv()

# # Configuration de l'API OpenAI
# openai.api_key = os.getenv('OPENAI_API_KEY')

# # Fonction pour g√©n√©rer une image √† partir du texte
# def generate_image_from_text(text_prompt):
#     try:
#         # Utilisation du mod√®le DALL¬∑E pour g√©n√©rer l'image √† partir du texte
#         response = openai.Image.create(
#             prompt=text_prompt,  # Description textuelle
#             n=1,  # Nombre d'images √† g√©n√©rer
#             size="1024x1024"  # Taille de l'image g√©n√©r√©e
#         )
#         # R√©cup√©rer l'URL de l'image g√©n√©r√©e
#         image_url = response['data'][0]['url']
#         return image_url
#     except Exception as e:
#         # Affichage d'une erreur si la g√©n√©ration √©choue
#         return f"Une erreur s'est produite lors de la g√©n√©ration de l'image: {e}"

# # Fonction pour interpr√©ter une image (d√©monstration)
# def interpret_image(image):
#     # Pour cette d√©mo, on affiche simplement l'image t√©l√©charg√©e
#     st.image(image, caption='Image interpr√©t√©e')

# # Application Streamlit
# st.title('G√©n√©rateur d\'image √† partir de texte')

# # Entr√©e utilisateur pour la description du texte
# text_input = st.text_input('Entrez une description pour g√©n√©rer une image', '')

# if text_input:
#     # G√©n√©rer l'image √† partir du texte
#     with st.spinner('G√©n√©ration de l\'image...'):
#         image_url = generate_image_from_text(text_input)
    
#     if image_url:
#         st.image(image_url, caption='Image g√©n√©r√©e', use_column_width=True)

# # Section d'analyse d'image
# st.subheader('Interpr√©tez une image')

# uploaded_file = st.file_uploader("T√©l√©chargez une image pour l'interpr√©tation", type=["jpg", "jpeg", "png"])

# if uploaded_file is not None:
#     # Affichage de l'image t√©l√©charg√©e
#     image = Image.open(uploaded_file)
#     st.image(image, caption="Image t√©l√©charg√©e", use_column_width=True)

#     # Interpr√©tation de l'image
#     with st.spinner('Interpr√©tation de l\'image...'):
#         interpret_image(image)


# import streamlit as st
# import requests
# from PIL import Image
# from io import BytesIO
# import os
# from dotenv import load_dotenv

# # Charger les variables d'environnement
# load_dotenv()

# # Cl√© d'API DeepAI (vous devez l'obtenir depuis https://deepai.org/machine-learning-model/text2img)
# DEEP_AI_API_KEY = os.getenv('DEEP_AI_API_KEY')

# # URL de l'API DeepAI pour g√©n√©rer une image
# DEEP_AI_URL = "https://api.deepai.org/api/text2img"

# # Fonction pour g√©n√©rer une image √† partir du texte via l'API DeepAI
# def generate_image_from_text(text_prompt):
#     response = requests.post(
#         DEEP_AI_URL,
#         data={'text': text_prompt},
#         headers={'api-key': DEEP_AI_API_KEY}
#     )
#     if response.status_code == 200:
#         image_url = response.json()['output_url']
#         return image_url
#     else:
#         return f"Erreur: {response.status_code}, {response.text}"

# # Application Streamlit
# st.title("G√©n√©rateur d'images √† partir de texte avec DeepAI")

# # Entr√©e utilisateur pour la description du texte
# text_input = st.text_input('Entrez une description pour g√©n√©rer une image', '')

# if text_input:
#     # G√©n√©rer l'image √† partir du texte
#     with st.spinner('G√©n√©ration de l\'image...'):
#         image_url = generate_image_from_text(text_input)

#     if 'Erreur' not in image_url:
#         st.image(image_url, caption="Image g√©n√©r√©e", use_column_width=True)
#     else:
#         st.error(image_url)

# # Section d'analyse d'image
# st.subheader('Interpr√©tez une image')

# uploaded_file = st.file_uploader("T√©l√©chargez une image pour l'interpr√©tation", type=["jpg", "jpeg", "png"])

# if uploaded_file is not None:
#     # Affichage de l'image t√©l√©charg√©e
#     image = Image.open(uploaded_file)
#     st.image(image, caption="Image t√©l√©charg√©e", use_column_width=True)


# import streamlit as st
# import requests
# from PIL import Image
# from io import BytesIO
# import os
# from dotenv import load_dotenv

# # Charger les variables d'environnement
# load_dotenv()

# # Cl√© d'API DeepAI (vous devez l'obtenir depuis https://deepai.org/machine-learning-model/text2img)
# DEEP_AI_API_KEY = os.getenv('DEEP_AI_API_KEY')

# # URL de l'API DeepAI pour g√©n√©rer une image
# DEEP_AI_URL = "https://api.deepai.org/api/text2img"

# # Fonction pour g√©n√©rer une image √† partir du texte via l'API DeepAI
# def generate_image_from_text(text_prompt):
#     if not DEEP_AI_API_KEY:
#         return "Cl√© API non trouv√©e ! Veuillez la configurer dans le fichier .env."
    
#     # Envoi de la requ√™te POST avec l'API key dans les headers
#     response = requests.post(
#         DEEP_AI_URL,
#         data={'text': text_prompt},
#         headers={'api-key': DEEP_AI_API_KEY}
#     )
    
#     # V√©rification du statut de la r√©ponse
#     if response.status_code == 200:
#         image_url = response.json()['output_url']
#         return image_url
#     else:
#         return f"Erreur: {response.status_code}, {response.text}"

# # Application Streamlit
# st.title("G√©n√©rateur d'images √† partir de texte avec DeepAI")

# # Entr√©e utilisateur pour la description du texte
# text_input = st.text_input('Entrez une description pour g√©n√©rer une image', '')

# if text_input:
#     # G√©n√©rer l'image √† partir du texte
#     with st.spinner('G√©n√©ration de l\'image...'):
#         image_url = generate_image_from_text(text_input)

#     if 'Erreur' not in image_url:
#         st.image(image_url, caption="Image g√©n√©r√©e", use_column_width=True)
#     else:
#         st.error(image_url)

# # Section d'analyse d'image
# st.subheader('Interpr√©tez une image')

# uploaded_file = st.file_uploader("T√©l√©chargez une image pour l'interpr√©tation", type=["jpg", "jpeg", "png"])

# if uploaded_file is not None:
#     # Affichage de l'image t√©l√©charg√©e
#     image = Image.open(uploaded_file)
#     st.image(image, caption="Image t√©l√©charg√©e", use_column_width=True)

# import streamlit as st
# import replicate
# import time
# from dotenv import load_dotenv
# import requests
# from PIL import Image
# from io import BytesIO

# load_dotenv()

# st.title("AI Image Generator")

# prompt = st.text_input("Enter a prompt for the image:")

# # Add a button to generate the image
# if st.button("Generate Image"):
#     with st.spinner('Generating image...'):
#         start_time = time.time()
#         output = replicate.run(
#             "stability-ai/sdxl:39ed52f2a78e934b3ba6e2a89f5b1c712de7dfea535525255b1aa35c5565e08b",
#             input={
#                 "width": 1024,
#                 "height": 1024,
#                 "prompt": prompt,
#                 "refine": "expert_ensemble_refiner",
#                 "num_outputs": 1,
#                 "apply_watermark": False,
#                 "negative_prompt": "low quality, worst quality",
#                 "num_inference_steps": 25
#             }
#         )
        
#         # The output is typically a list with one or more image URLs
#         if output and len(output) > 0:
#             # Get the first image URL
#             image_url = output[0]
            
#             # Download the image
#             response = requests.get(image_url)
#             if response.status_code == 200:
#                 # Convert the image data to a format Streamlit can display
#                 image = Image.open(BytesIO(response.content))
#                 # Display the generated image
#                 st.image(image)
                
#                 end_time = time.time()
#                 elapsed_time = end_time - start_time
#                 st.write(f"Image generated in {elapsed_time:.2f} seconds")
#             else:
#                 st.error("Failed to download the generated image")
#         else:
#             st.error("No image was generated")


# import streamlit as st
# import os
# import numpy as np
# import pandas as pd
# import urllib.request
# from PIL import Image
# import glob


# def update_params():
#     st.experimental_set_query_params(challenge=st.session_state.day)


# md_files = sorted(
#     [int(x.strip("Day").strip(".md")) for x in glob.glob1("content", "*.md")]
# )

# # Logo and Navigation
# col1, col2, col3 = st.columns((1, 4, 1))
# with col2:
#     st.image(Image.open("C:/Users/Empire/Downloads/streamlit-logo-secondary-colormark-darktext.png"))
# st.markdown("# 30 Days of Streamlit en Fran√ßais! üá´üá∑")

# days_list = [f"Day {x}" for x in md_files]

# query_params = st.experimental_get_query_params()

# if query_params and query_params["challenge"][0] in days_list:
#     st.session_state.day = query_params["challenge"][0]

# selected_day = st.selectbox(
#     "Choisissez votre d√©fi üëá", days_list, key="day", on_change=update_params
# )

# with st.expander("√Ä propos du challenge #30DaysOfStreamlit"):
#     st.markdown(
#         """

#     Le **#30DaysOfStreamlit** est un d√©fi con√ßu pour vous aider √† d√©marrer dans la cr√©ation d'applications Streamlit.
    
#      Vous pourrez notamment :
#      - Configurer un environnement pour cr√©er des apps Streamlit
#      - Cr√©ez votre premi√®re app
#      - D√©couvrir l'√©ventail des widgets √† utiliser pour votre application!
#     """
#     )
#     st.write("")

# # Sidebar

# st.sidebar.header("√Ä propos")
# st.sidebar.markdown(
#     "[Streamlit](https://streamlit.io) est une biblioth√®que open source Python qui permet la cr√©ation d'applications Web interactives tr√®s facilement!"
# )

# st.sidebar.header("Resources")
# st.sidebar.markdown(
#     """
# - [Documentation de Streamlit](https://docs.streamlit.io/)
# - [Cheat sheet](https://docs.streamlit.io/library/cheatsheet)
# - [Ouvrage](https://www.amazon.com/dp/180056550X) (Getting Started with Streamlit for Data Science)
# - [Blog](https://blog.streamlit.io/how-to-master-streamlit-for-data-science/) (How to master Streamlit for data science)
# """
# )

# st.sidebar.header("D√©ploiement")
# st.sidebar.markdown(
#     "D√©ployez vos applications Streamlit √† l'aide de [Streamlit Community Cloud](https://streamlit.io/cloud) en quelques clics!"
# )

# # Display content
# for i in days_list:
#     if selected_day == i:
#         st.markdown(f"# üóìÔ∏è {i}")
#         j = i.replace(" ", "")
#         with open(f"content/{j}.md", "r") as f:
#             st.markdown(f.read())
#         if os.path.isfile(f"content/figures/{j}.csv") == True:
#             st.markdown("---")
#             st.markdown("### Figure #01")
#             df = pd.read_csv(f"content/figures/{j}.csv", engine="python")
#             for i in range(len(df)):
#                 st.image(f"content/images/{df.img[i]}")
#                 st.info(f"{df.figure[i]}: {df.caption[i]}")


#streamlit run app.py
import streamlit as st
import replicate
import time
from dotenv import load_dotenv

load_dotenv()

st.title("AI Image Generator")

prompt = st.text_input("Enter a prompt for the image:")

# Add a button to generate the image
if st.button("Generate Image"):
    with st.spinner('Generating image...'):
        start_time = time.time()
        output = replicate.run(
            "stability-ai/sdxl:39ed52f2a78e934b3ba6e2a89f5b1c712de7dfea535525255b1aa35c5565e08b",
            input={
                "width": 1024,
                "height": 1024,
                "prompt": prompt,
                "refine": "expert_ensemble_refiner",
                "num_outputs": 1,
                "apply_watermark": False,
                "negative_prompt": "low quality, worst quality",
                "num_inference_steps": 25
            }
        )

        # Display the generated image
        st.image(output)
        end_time = time.time()
        elapsed_time = end_time - start_time
        st.write(f"Image generated in {elapsed_time:.2f} seconds")

# import streamlit as st
# import replicate
# import time
# import os
# from dotenv import load_dotenv

# # Charger les variables d'environnement √† partir du fichier .env
# load_dotenv()

# # R√©cup√©rer le token API Replicate depuis le fichier .env
# REPLICATE_API_TOKEN = os.getenv('REPLICATE_API_TOKEN')

# # V√©rifier si le token est bien charg√©
# if not REPLICATE_API_TOKEN:
#     st.error("Le token API Replicate n'a pas √©t√© trouv√©. Assurez-vous qu'il est dans votre fichier .env.")
# else:
#     replicate.Client(api_token=REPLICATE_API_TOKEN)  # Authentifier le client Replicate avec le token

# def generate_image():
#     st.subheader("Generate Image")
#     prompt = st.text_input(label="Enter a prompt for the image:", key="generate_image_prompt")

#     if st.button("Generate Image", key="generate_image_button"):
#         with st.spinner("Generating image..."):
#             start_time = time.time()
            
#             try:
#                 # Effectuer l'appel √† l'API Replicate pour g√©n√©rer l'image
#                 output = replicate.run(
#                     "stability-ai/sdxl:39ed52f2a78e934b3ba6e2a89f5b1c712de7dfea535525255b1aa35c5565e08b",
#                     input={
#                         "width": 1024,
#                         "height": 1024,
#                         "prompt": prompt,
#                         "refine": "expert_ensemble_refiner",
#                         "num_outputs": 1,
#                         "apply_watermark": False,
#                         "negative_prompt": "low quality, worst quality",
#                         "num_inference_steps": 25
#                     }
#                 )

#                 # Afficher l'image g√©n√©r√©e
#                 st.image(output)
#                 end_time = time.time()
#                 elapsed_time = end_time - start_time
#                 st.write(f"Image generated in {elapsed_time:.2f} seconds")
#             except Exception as e:
#                 st.error(f"An error occurred: {str(e)}")
